---
title: "W203 Supplementary Exercise 2"
author: "Mohammad Jawad Habib"
date: "February 21, 2016"
output: pdf_document
---

1. Write a function in R that does the following:
Takes sample data (e.g., as a vector), mean of the null hypothesis, population standard deviation,  a Boolean variable indicating whether we want a one-tailed or two-tailed test, and another Boolean variable indicating which tail (left or right) should be taken in case of a one-tailed test. Returns p-values for the required test (Null is “population mean is the one that the function is fed”), as well as a Boolean value showing whether the test passes a conventional 5% level or not.

```{r}
myfun <- function(data, mu, pop.sd, two.tailed=TRUE, left.tail=NULL) {
  # we only want to deal with a numeric vector
  if(!is.numeric(data)) stop("'data' must be a numeric vector \n")
  
  # we expect 'left.tail' to be TRUE or FALSE for one-tailed test
  if(!two.tailed & is.null(left.tail)) 
    stop("'left.tail' must be TRUE or FALSE for one tailed test \n")
  
  # calculate z-score
  z.raw <- (mean(data) - mu) / (pop.sd/(sqrt(length(data))))
  
  # convert p-value to two-tailed if applicable
  if(two.tailed) {
    p.val <- 2*pnorm(-abs(z.raw), lower.tail = TRUE)
    rejectNull <- ifelse(p.val < 0.025, TRUE, FALSE)
  } else {
    if(left.tail == TRUE) { # left-tailed
      # take the area to the left of z.raw
      p.val <- pnorm(z.raw, lower.tail = TRUE)
    } else { # right-tailed
      # take the area to the right of z.raw
      p.val <- pnorm(z.raw, lower.tail = FALSE)
    }
    rejectNull <- ifelse(p.val < 0.05, TRUE, FALSE)
  }
  
  (list("p.value" = p.val, "rejectNull" = rejectNull))
}
```

Seed the RNG for repeatable results.
```{r}
set.seed(5000)
```

2. Choose a sample size and then use `rnorm(n, mean, sd)` to generate a random sample and test your function.
```{r}
pop_mean <- 50
pop_sd <- 21
sample_size <- 36
sample_data <- rnorm(sample_size, mean = pop_mean, sd = pop_sd)

# run a two-tailed test
myfun(sample_data, mu = pop_mean, pop.sd = pop_sd, two.tailed = TRUE, left.tail = NULL)

# run a left-tailed test
myfun(sample_data, mu = pop_mean, pop.sd = pop_sd, two.tailed = FALSE, left.tail = TRUE)

# run a right tailed test
myfun(sample_data, mu = pop_mean, pop.sd = pop_sd, two.tailed = FALSE, left.tail = FALSE)
```


3. Use replicate or sapply (or replicate) to generate a sample and do the test multiple times (say 1000). Plot the histogram of p-values that you are getting when the Null is true. Is your function calculating Type-I errors correctly?
```{r}
num.trials <- 1000

result.vec.two.tailed <- replicate(num.trials, 
                                   myfun(rnorm(sample_size, mean = pop_mean, sd = pop_sd), 
                                         mu = pop_mean, 
                                         pop.sd = pop_sd, 
                                         two.tailed = TRUE, 
                                         left.tail = NULL)$p.value, 
                                   simplify = TRUE)
hist(result.vec.two.tailed)

result.vec.left.tailed <- replicate(num.trials, 
                                   myfun(rnorm(sample_size, mean = pop_mean, sd = pop_sd), 
                                         mu = pop_mean, 
                                         pop.sd = pop_sd, 
                                         two.tailed = FALSE, 
                                         left.tail = TRUE)$p.value, 
                                   simplify = TRUE)
hist(result.vec.left.tailed)


result.vec.right.tailed <- replicate(num.trials, 
                                    myfun(rnorm(sample_size, mean = pop_mean, sd = pop_sd), 
                                          mu = pop_mean, 
                                          pop.sd = pop_sd, 
                                          two.tailed = FALSE, 
                                          left.tail = FALSE)$p.value, 
                                    simplify = TRUE)
hist(result.vec.right.tailed)
```

We can test below whether we are returning `TRUE` or `FALSE` correctly from `myfun`.
```{r}
result.vec.right.tailed <- replicate(num.trials, 
                                    myfun(rnorm(sample_size, mean = pop_mean, sd = pop_sd), 
                                          mu = pop_mean, 
                                          pop.sd = pop_sd, 
                                          two.tailed = FALSE, 
                                          left.tail = FALSE), 
                                    simplify = TRUE)
df <- data.frame(cbind(result.vec.right.tailed[1,], result.vec.right.tailed[2,]))
colnames(df) <- c("p.value", "rejectNull")
head(df)
```

4. Now assume your Null is false. Note: For type-II error calculation, you need a specific assumption about the mean of the population from which the sample is taken. 
You can assume that this mean is one tenth of one standard deviation above the Null mean.
Calculate type-II errors both theoretically and by simulation as in step 3.

`sample_data` represents our test vector with population mean of `pop_mean` and population sd of `pop_sd`. We assume that `mean(sample_data)` is our null hypothesis in this case.

The questions specifies a mean value (we will call this `rejection.mean`). 

## Perform a right-tailed test
For a right-tailed test, any values above this `rejection.mean` will cause us to reject the null hypothesis.
```{r}
rejection.mean <- pop_mean + pop_sd/10
rejection.mean
```
For original population with mean pop_mean, rejection.mean represents a z-score of `z.pop` given below.
```{r}
z.pop <- (rejection.mean - pop_mean) / 
  (pop_sd/sqrt(length(sample_data)))
z.pop
```

Assuming that Null `pop_mean` is False, we take `mean(sample_data)` as our Null hypothesis
That is, we use a distribution with `mean(sample_data)`.

For Type I error, we will use the original population distribution where Null is given by `pop_mean`. Type I error is the area to the right of `rejection.mean` on the original population distribution for a right-tailed test.
```{r}
z.type.one.right <- (rejection.mean - pop_mean) / 
  (pop_sd/sqrt(length(sample_data)))
z.type.one.right
p.type.one.right <- pnorm(z.type.one.right, lower.tail = FALSE)
p.type.one.right
```

Type II error is the area to the left of `rejection.mean` on the alternate distribution with mean equal to `mean(sample_data)`.
```{r}
z.type.two.right <- (rejection.mean - mean(sample_data)) / 
  (pop_sd/sqrt(length(sample_data)))
z.type.two.right

# For Type II, this time we want the area to the left of z.type.two.right on alternate distribution
p.type.two.right <- pnorm(z.type.two.right, lower.tail = TRUE)
p.type.two.right

test.power.right <- 1 - p.type.two.right
test.power.right
```
For a right-tailed test, there is a probability given by `p.type.two.right` that we will fail to reject the null hypothesis when we should. This is our Type II error in this case.

## Perform a left-tailed test
In a left-tailed test, Type I error is area to the left of `rejection.mean` on the original distribution with mean `pop_mean`.
```{r}
z.type.one.left <- (rejection.mean - mean(sample_data)) / 
  (pop_sd/sqrt(length(sample_data)))
z.type.one.left

p.type.one.left <- pnorm(z.type.one.left, lower.tail = TRUE)
p.type.one.left
```

In a left tailed test, Type II error is given by the area to the right of `rejection.mean` on the alternate distribution with mean equal to `mean(sample_data)`.

```{r}
# z-value in this case is the same as z.type.two.right but let's calculate it anyways
z.type.two.left <- (rejection.mean - mean(sample_data)) / 
  (pop_sd/sqrt(length(sample_data)))
z.type.two.left

# For Type II, this time we want the area to the right of z.type.two.left on alternate distribution
p.type.two.left <- pnorm(z.type.two.left, lower.tail = FALSE)
p.type.two.left

test.power.left <- 1 - p.type.two.left
test.power.left

```
For a left-tailed test, there is a probability given by `p.type.two.left` that we will fail to reject the null hypothesis when we should. This is our Type II error in this case.

## Perform a two-tailed test
In a two-tailed test, rejection region is to the left of -alpha/2 and to the right of alpha/2 on the original distribution.
```{r}
z.original <- (rejection.mean - pop_mean) / (pop_sd/(sqrt(length(sample_data))))
z.original

# Type I error is the same as the value given below
p.type.one.twotailed <- pnorm(z.original, lower.tail=FALSE)
p.type.one.twotailed

alpha_by_two <- p.type.one.twotailed/2
alpha_by_two

z.alpha_by_two.pos <- qnorm(alpha_by_two, lower.tail = FALSE) 
z.alpha_by_two.pos

rejection.mean.twotailed.pos <- pop_mean + 
  z.alpha_by_two.pos*(pop_sd/sqrt(length(sample_data)))
rejection.mean.twotailed.pos

z.alpha_by_two.neg <- -z.alpha_by_two.pos

rejection.mean.twotailed.neg <- pop_mean + 
  z.alpha_by_two.neg*(pop_sd/sqrt(length(sample_data)))
rejection.mean.twotailed.neg
```

To calculate Type II error, we will first get the z-scores for our `rejection.mean.twotailed.pos` and `rejection.mean.twotailed.neg` on the alternate distribution. Then we will use `pnorm` to get the regions to the right and left of the positive and negative z-scores on the alternate distribution. We will then calculate Type II error by subtracting those two values from 1.
```{r}
# For the positive rejection.mean.two.tailed
z.twotailed.positive <- (rejection.mean.twotailed.pos - mean(sample_data)) / 
  (pop_sd/sqrt(length(sample_data)))
z.twotailed.positive

p.twotailed.positive <- pnorm(z.twotailed.positive, lower.tail = FALSE)
p.twotailed.positive

z.twotailed.negative <- (rejection.mean.twotailed.neg - mean(sample_data)) / 
  (pop_sd/sqrt(length(sample_data)))
z.twotailed.negative

p.twotailed.negative <- pnorm(z.twotailed.negative, lower.tail = TRUE)
p.twotailed.negative
```

Finally, we can calculate our Type II error for a two-tailed test using the alternative distribution and the power of test.
```{r}
p.type.two.twotailed <- 1 - p.twotailed.positive - p.twotailed.negative
p.type.two.twotailed

test.power.twotailed <- 1 - p.type.two.twotailed
test.power.twotailed
```